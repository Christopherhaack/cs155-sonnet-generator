{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "from sklearn.externals import joblib\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = joblib.load('../models/hmm_10.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6751"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = model.transmat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "O = model.emissionprob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_start = model.startprob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = json.load(open('../models/shakespeare_words/shakespeare_vocab.json'))\n",
    "\n",
    "for k in vocab.keys():\n",
    "    vocab[int(k)] = vocab.pop(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inverted_vocab = json.load(open('../models/shakespeare_words/shakespeare_inverted_vocab.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meter = json.load(open('../models/shakespeare_words/shakespeare_meter.json'))\n",
    "inverted_meter = json.load(open('../models/shakespeare_words/shakespeare_inverted_meter.json'))\n",
    "        \n",
    "word2vec = gensim.models.Word2Vec.load('../models/word2vec.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_pick(l, probs):\n",
    "    \"\"\" \n",
    "    Probabilistic random picking according\n",
    "    to a probability distribution\n",
    "    \"\"\"\n",
    "    x = random.uniform(0, 0.999)\n",
    "    cumulative_probability = 0.0\n",
    "\n",
    "    for item, prob in zip(l, probs):\n",
    "        cumulative_probability += prob\n",
    "        if x < cumulative_probability: \n",
    "            break\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L, D = O.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_next(num_syllables, previous_word, probs):\n",
    "    new_probs = np.copy(probs)\n",
    "    \n",
    "    # Filter based on meter, and keep syllables 11 or under\n",
    "    invalid = []\n",
    "    for k in meter.keys():\n",
    "        m = map(int, k.split(','))\n",
    "        if m[0] != num_syllables % 2:\n",
    "            invalid.extend([inverted_vocab[w] for w in meter[k]])\n",
    "        \n",
    "        if len(m) + num_syllables > 10:\n",
    "            invalid.extend([inverted_vocab[w] for w in meter[k]])\n",
    "            \n",
    "    new_probs[invalid] = 0\n",
    "    with np.errstate(divide='ignore'):\n",
    "        new_probs = np.divide(new_probs, np.sum(new_probs))\n",
    "        \n",
    "        new_probs[new_probs == np.inf] = 0\n",
    "        new_probs = np.nan_to_num(new_probs)\n",
    "    \n",
    "    \n",
    "    return new_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_line(start_word):\n",
    "    emission = []\n",
    "    \n",
    "    num_syllables = 0    \n",
    "        \n",
    "    start = inverted_vocab[start_word]\n",
    "    state = random_pick(range(L), \\\n",
    "                    np.divide(O[:, start], np.sum(O[:, start])))\n",
    "            \n",
    "    num_syllables += len(inverted_meter[start_word][0].split(','))\n",
    "    emission.append(start_word)\n",
    "\n",
    "    prev_word = start_word\n",
    "    while num_syllables < 10:\n",
    "        # Sample next observation.\n",
    "        next_probs = filter_next(num_syllables, prev_word, O[state, :])    \n",
    "        next_obs= random_pick(range(D), next_probs)\n",
    "            \n",
    "        try:\n",
    "            next_word = vocab[next_obs]    \n",
    "            if (next_word == \"'\"): # This somehow showed up as word, skip\n",
    "                continue\n",
    "                \n",
    "            emission.append(next_word)\n",
    "            stresses = inverted_meter[next_word][0].split(',')\n",
    "            \n",
    "            num_syllables += len(stresses)\n",
    "            prev_word = next_word\n",
    "            \n",
    "            next_state = random_pick(range(L), A[state, :])\n",
    "            state = next_state\n",
    "                \n",
    "        except KeyError: # shouldn't occur, but just in case\n",
    "            continue\n",
    "                \n",
    "    return emission\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def start_next(prev_start):\n",
    "    w, p = zip(*word2vec.most_similar(prev_start, topn=30))\n",
    "\n",
    "    w = list(w)\n",
    "    # Make sure it starts out with unstressed\n",
    "    starts = []\n",
    "    for word in w:\n",
    "        stresses = inverted_meter[word][0].split(',')\n",
    "        if (stresses[0] == '0'):\n",
    "            starts.append(word)\n",
    "    \n",
    "    if len(starts) == 0:\n",
    "        return prev_start\n",
    "    return np.random.choice(starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_sonnet(start_word):\n",
    "    sonnet = ''\n",
    "    for i in xrange(14):\n",
    "        line = generate_line(start_word)\n",
    "        sonnet += ' '.join(line)\n",
    "        if ((i + 1) % 4 == 0) or (i == 13):\n",
    "            sonnet += '.\\n'\n",
    "        else:\n",
    "            sonnet += ',\\n'\n",
    "            \n",
    "        start_word = start_next(start_word)\n",
    "    return sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "years music threat this careful cheek can help,\n",
      "concealing and afeard that handmaids place,\n",
      "slumbers excuse is gardens sour will note,\n",
      "all-hurting greater harder happy youth.\n",
      "'he thou disjoin'd it look to thy deceased,\n",
      "provoke it make an resolution sad,\n",
      "attorney master like him like the oaths,\n",
      "comparing then than those simplicity.\n",
      "distraction place to downright my receives,\n",
      "gather'd them weep the sacred love's are do,\n",
      "distraction wind of tenure hang from thy,\n",
      "gather'd befriends with my just year with my.\n",
      "desire then the treason in the red,\n",
      "upon to look suggest of my besieged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print generate_sonnet('years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rhyme = json.load(open('../models/shakespeare_words/shakespeare_rhyme.json'))\n",
    "\n",
    "inverted_rhyme = json.load( \\\n",
    "            open('../models/shakespeare_words/shakespeare_inverted_rhyme.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
